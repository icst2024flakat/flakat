{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/vyj613fs57b4g86vrn1xc5t80000gn/T/ipykernel_1159/552859148.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  switchedCSV['category'] = dataCSV['category']\n",
      "/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "dataCSV = pd.read_csv('extracted-all-projects.csv')\n",
    "vectorCSV = pd.read_csv('vector.csv')\n",
    "\n",
    "raw = dataCSV['raw']\n",
    "dataCSV['id']=range(1, len(dataCSV) + 1)\n",
    "vectorCSV['id']=range(1, len(vectorCSV) + 1)\n",
    "switchedCSV = vectorCSV[['id','name','feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9','feature_10','feature_11','feature_12','feature_13','feature_14','feature_15','feature_16','feature_17','feature_18','feature_19','feature_20','feature_21','feature_22','feature_23','feature_24','feature_25','feature_26','feature_27','feature_28','feature_29','feature_30','feature_31','feature_32','feature_33','feature_34','feature_35','feature_36','feature_37','feature_38','feature_39','feature_40','feature_41','feature_42','feature_43','feature_44','feature_45','feature_46','feature_47','feature_48','feature_49','feature_50','feature_51','feature_52','feature_53','feature_54','feature_55','feature_56','feature_57','feature_58','feature_59','feature_60','feature_61','feature_62','feature_63','feature_64','feature_65','feature_66','feature_67','feature_68','feature_69','feature_70','feature_71','feature_72','feature_73','feature_74','feature_75','feature_76','feature_77','feature_78','feature_79','feature_80','feature_81','feature_82','feature_83','feature_84','feature_85','feature_86','feature_87','feature_88','feature_89','feature_90','feature_91','feature_92','feature_93','feature_94','feature_95','feature_96','feature_97','feature_98','feature_99','feature_100','feature_101','feature_102','feature_103','feature_104','feature_105','feature_106','feature_107','feature_108','feature_109','feature_110','feature_111','feature_112','feature_113','feature_114','feature_115','feature_116','feature_117','feature_118','feature_119','feature_120','feature_121','feature_122','feature_123','feature_124','feature_125','feature_126','feature_127','feature_128','feature_129','feature_130','feature_131','feature_132','feature_133','feature_134','feature_135','feature_136','feature_137','feature_138','feature_139','feature_140','feature_141','feature_142','feature_143','feature_144','feature_145','feature_146','feature_147','feature_148','feature_149','feature_150','feature_151','feature_152','feature_153','feature_154','feature_155','feature_156','feature_157','feature_158','feature_159','feature_160','feature_161','feature_162','feature_163','feature_164','feature_165','feature_166','feature_167','feature_168','feature_169','feature_170','feature_171','feature_172','feature_173','feature_174','feature_175','feature_176','feature_177','feature_178','feature_179','feature_180','feature_181','feature_182','feature_183','feature_184','feature_185','feature_186','feature_187','feature_188','feature_189','feature_190','feature_191','feature_192','feature_193','feature_194','feature_195','feature_196','feature_197','feature_198','feature_199','feature_200','feature_201','feature_202','feature_203','feature_204','feature_205','feature_206','feature_207','feature_208','feature_209','feature_210','feature_211','feature_212','feature_213','feature_214','feature_215','feature_216','feature_217','feature_218','feature_219','feature_220','feature_221','feature_222','feature_223','feature_224','feature_225','feature_226','feature_227','feature_228','feature_229','feature_230','feature_231','feature_232','feature_233','feature_234','feature_235','feature_236','feature_237','feature_238','feature_239','feature_240','feature_241','feature_242','feature_243','feature_244','feature_245','feature_246','feature_247','feature_248','feature_249','feature_250','feature_251','feature_252','feature_253','feature_254','feature_255','feature_256','feature_257','feature_258','feature_259','feature_260','feature_261','feature_262','feature_263','feature_264','feature_265','feature_266','feature_267','feature_268','feature_269','feature_270','feature_271','feature_272','feature_273','feature_274','feature_275','feature_276','feature_277','feature_278','feature_279','feature_280','feature_281','feature_282','feature_283','feature_284','feature_285','feature_286','feature_287','feature_288','feature_289','feature_290','feature_291','feature_292','feature_293','feature_294','feature_295','feature_296','feature_297','feature_298','feature_299','feature_300','feature_301','feature_302','feature_303','feature_304','feature_305','feature_306','feature_307','feature_308','feature_309','feature_310','feature_311','feature_312','feature_313','feature_314','feature_315','feature_316','feature_317','feature_318','feature_319','feature_320','feature_321','feature_322','feature_323','feature_324','feature_325','feature_326','feature_327','feature_328','feature_329','feature_330','feature_331','feature_332','feature_333','feature_334','feature_335','feature_336','feature_337','feature_338','feature_339','feature_340','feature_341','feature_342','feature_343','feature_344','feature_345','feature_346','feature_347','feature_348','feature_349','feature_350','feature_351','feature_352','feature_353','feature_354','feature_355','feature_356','feature_357','feature_358','feature_359','feature_360','feature_361','feature_362','feature_363','feature_364','feature_365','feature_366','feature_367','feature_368','feature_369','feature_370','feature_371','feature_372','feature_373','feature_374','feature_375','feature_376','feature_377','feature_378','feature_379','feature_380','feature_381','feature_382','feature_383']]\n",
    "switchedCSV['category'] = dataCSV['category']\n",
    "switchedCSV['category'].replace(np.nan, 'NonFlaky', inplace=True)\n",
    "switchedCSV = switchedCSV[(switchedCSV['category'] == 'ID') | (switchedCSV['category'] == 'UD') |(switchedCSV['category'] == 'OD') | (switchedCSV['category'] == 'OD-Vic') | (switchedCSV['category'] == 'OD-Brit') | (switchedCSV['category'] == 'NOD') | (switchedCSV['category'] == 'NDOD') | (switchedCSV['category'] == 'NODI')]\n",
    "features = ['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9','feature_10','feature_11','feature_12','feature_13','feature_14','feature_15','feature_16','feature_17','feature_18','feature_19','feature_20','feature_21','feature_22','feature_23','feature_24','feature_25','feature_26','feature_27','feature_28','feature_29','feature_30','feature_31','feature_32','feature_33','feature_34','feature_35','feature_36','feature_37','feature_38','feature_39','feature_40','feature_41','feature_42','feature_43','feature_44','feature_45','feature_46','feature_47','feature_48','feature_49','feature_50','feature_51','feature_52','feature_53','feature_54','feature_55','feature_56','feature_57','feature_58','feature_59','feature_60','feature_61','feature_62','feature_63','feature_64','feature_65','feature_66','feature_67','feature_68','feature_69','feature_70','feature_71','feature_72','feature_73','feature_74','feature_75','feature_76','feature_77','feature_78','feature_79','feature_80','feature_81','feature_82','feature_83','feature_84','feature_85','feature_86','feature_87','feature_88','feature_89','feature_90','feature_91','feature_92','feature_93','feature_94','feature_95','feature_96','feature_97','feature_98','feature_99','feature_100','feature_101','feature_102','feature_103','feature_104','feature_105','feature_106','feature_107','feature_108','feature_109','feature_110','feature_111','feature_112','feature_113','feature_114','feature_115','feature_116','feature_117','feature_118','feature_119','feature_120','feature_121','feature_122','feature_123','feature_124','feature_125','feature_126','feature_127','feature_128','feature_129','feature_130','feature_131','feature_132','feature_133','feature_134','feature_135','feature_136','feature_137','feature_138','feature_139','feature_140','feature_141','feature_142','feature_143','feature_144','feature_145','feature_146','feature_147','feature_148','feature_149','feature_150','feature_151','feature_152','feature_153','feature_154','feature_155','feature_156','feature_157','feature_158','feature_159','feature_160','feature_161','feature_162','feature_163','feature_164','feature_165','feature_166','feature_167','feature_168','feature_169','feature_170','feature_171','feature_172','feature_173','feature_174','feature_175','feature_176','feature_177','feature_178','feature_179','feature_180','feature_181','feature_182','feature_183','feature_184','feature_185','feature_186','feature_187','feature_188','feature_189','feature_190','feature_191','feature_192','feature_193','feature_194','feature_195','feature_196','feature_197','feature_198','feature_199','feature_200','feature_201','feature_202','feature_203','feature_204','feature_205','feature_206','feature_207','feature_208','feature_209','feature_210','feature_211','feature_212','feature_213','feature_214','feature_215','feature_216','feature_217','feature_218','feature_219','feature_220','feature_221','feature_222','feature_223','feature_224','feature_225','feature_226','feature_227','feature_228','feature_229','feature_230','feature_231','feature_232','feature_233','feature_234','feature_235','feature_236','feature_237','feature_238','feature_239','feature_240','feature_241','feature_242','feature_243','feature_244','feature_245','feature_246','feature_247','feature_248','feature_249','feature_250','feature_251','feature_252','feature_253','feature_254','feature_255','feature_256','feature_257','feature_258','feature_259','feature_260','feature_261','feature_262','feature_263','feature_264','feature_265','feature_266','feature_267','feature_268','feature_269','feature_270','feature_271','feature_272','feature_273','feature_274','feature_275','feature_276','feature_277','feature_278','feature_279','feature_280','feature_281','feature_282','feature_283','feature_284','feature_285','feature_286','feature_287','feature_288','feature_289','feature_290','feature_291','feature_292','feature_293','feature_294','feature_295','feature_296','feature_297','feature_298','feature_299','feature_300','feature_301','feature_302','feature_303','feature_304','feature_305','feature_306','feature_307','feature_308','feature_309','feature_310','feature_311','feature_312','feature_313','feature_314','feature_315','feature_316','feature_317','feature_318','feature_319','feature_320','feature_321','feature_322','feature_323','feature_324','feature_325','feature_326','feature_327','feature_328','feature_329','feature_330','feature_331','feature_332','feature_333','feature_334','feature_335','feature_336','feature_337','feature_338','feature_339','feature_340','feature_341','feature_342','feature_343','feature_344','feature_345','feature_346','feature_347','feature_348','feature_349','feature_350','feature_351','feature_352','feature_353','feature_354','feature_355','feature_356','feature_357','feature_358','feature_359','feature_360','feature_361','feature_362','feature_363','feature_364','feature_365','feature_366','feature_367','feature_368','feature_369','feature_370','feature_371','feature_372','feature_373','feature_374','feature_375','feature_376','feature_377','feature_378','feature_379','feature_380','feature_381','feature_382','feature_383']\n",
    "vector_val = switchedCSV[features]\n",
    "vector_cat = switchedCSV['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Process Objective: High accuracy in flaky test classification (do f1s first)\n",
    "2. Design Parameters: \n",
    "    All hyperparameters for sklearn RandomForest \n",
    "    {'bootstrap': True,\n",
    "    'ccp_alpha': 0.0,\n",
    "    'class_weight': None,\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_leaf_nodes': None,\n",
    "    'max_samples': None,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2,\n",
    "    'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 100,\n",
    "    'n_jobs': None,\n",
    "    'oob_score': False,\n",
    "    'random_state': None,\n",
    "    'verbose': 0,\n",
    "    'warm_start': False}\n",
    "\n",
    "    out of the above, these are tunable hyperparameter that affect the result\n",
    "    \n",
    "    criterion,min_impurity_decrease,min_samples_leaf,n_estimators\n",
    "\n",
    "    TODO: try the process without pruning the meaningful of features\n",
    "\n",
    "    ccp_alpha,criterion,max_depth,max_features,max_leaf_nodes,max_samples,min_impurity_decrease,min_samples_leaf,min_samples_split,min_weight_fraction_leaf,n_estimators\n",
    "\n",
    "    11 parameters. Use L27 with last two parameters ignored.\n",
    "\n",
    "3. Orthogonal array L9, 3 values for the 4 parameters above\n",
    "\n",
    "4. performance measure though, should it be categorical? should it be balanced? should it be precision/recall/f1s or others?\n",
    "    right now do f1s\n",
    "\n",
    "5. analysis \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['gini', 0, 20, 50], ['gini', 0.001, 40, 100], ['gini', 0.01, 60, 150], ['entropy', 0, 40, 150], ['entropy', 0.001, 60, 50], ['entropy', 0.01, 20, 100], ['log_loss', 0, 60, 100], ['log_loss', 0.001, 20, 150], ['log_loss', 0.01, 40, 50]]\n"
     ]
    }
   ],
   "source": [
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "min_impurity_decrease = [ 0, 0.001, 0.01]\n",
    "min_samples_leaf = [20, 40, 60]\n",
    "n_estimators = [50, 100, 150]\n",
    "\n",
    "runConfig = []\n",
    "runConfig.append([criterion[0], min_impurity_decrease[0], min_samples_leaf[0], n_estimators[0]])\n",
    "runConfig.append([criterion[0], min_impurity_decrease[1], min_samples_leaf[1], n_estimators[1]])\n",
    "runConfig.append([criterion[0], min_impurity_decrease[2], min_samples_leaf[2], n_estimators[2]])\n",
    "runConfig.append([criterion[1], min_impurity_decrease[0], min_samples_leaf[1], n_estimators[2]])\n",
    "runConfig.append([criterion[1], min_impurity_decrease[1], min_samples_leaf[2], n_estimators[0]])\n",
    "runConfig.append([criterion[1], min_impurity_decrease[2], min_samples_leaf[0], n_estimators[1]])\n",
    "runConfig.append([criterion[2], min_impurity_decrease[0], min_samples_leaf[2], n_estimators[1]])\n",
    "runConfig.append([criterion[2], min_impurity_decrease[1], min_samples_leaf[0], n_estimators[2]])\n",
    "runConfig.append([criterion[2], min_impurity_decrease[2], min_samples_leaf[1], n_estimators[0]])\n",
    "print(runConfig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samplingSMOTEandTL(vector_val, vector_cat):\n",
    "    smote = SMOTE()\n",
    "    X_smote, y_smote = smote.fit_resample(vector_val, vector_cat)\n",
    "\n",
    "    tl = TomekLinks()\n",
    "    X_tl, y_tl = tl.fit_resample(X_smote, y_smote)\n",
    "\n",
    "    return X_tl, y_tl\n",
    "\n",
    "def runCategorySpecificKFold(classifier, fold, embedding, output, metrics):\n",
    "\n",
    "    kf = KFold(n_splits=fold, shuffle=True)\n",
    "    result_dict = {}\n",
    "    unique, counts = np.unique(output, return_counts=True)\n",
    "    for category in unique:\n",
    "        result_dict[category] = {}\n",
    "        if 'precision' in metrics:\n",
    "            result_dict[category]['precision'] = []\n",
    "        if 'recall' in metrics:\n",
    "            result_dict[category]['recall'] = []\n",
    "        if 'f1s' in metrics:\n",
    "            result_dict[category]['f1s'] = []\n",
    "        if 'mcc' in metrics:\n",
    "            result_dict[category]['mcc'] = []\n",
    "        if 'fdc' in metrics:\n",
    "            result_dict[category]['fdc'] = []\n",
    "\n",
    "    for train_index, test_index in kf.split(embedding):\n",
    "        \n",
    "        X_train, X_test = embedding[train_index], embedding[test_index]\n",
    "        y_train, y_test = output[train_index], output[test_index]\n",
    "\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        cm = confusion_matrix(y_test,y_pred,labels=unique)\n",
    "\n",
    "        FP = np.sum(cm, axis=0) - np.diag(cm)\n",
    "        FN = np.sum(cm, axis=1) - np.diag(cm)\n",
    "        TP = np.diag(cm)\n",
    "        TN = cm[:].sum() - (FP + FN + TP)\n",
    "\n",
    "        TP = np.asarray([1 if x==0 else x for x in TP], dtype=np.int)\n",
    "        \n",
    "        if 'precision' in metrics:\n",
    "            precision = TP/(TP+FN)\n",
    "        if 'recall' in metrics:\n",
    "            recall = TP/(TP+FP)\n",
    "        if 'f1s' in metrics:\n",
    "            f1score = TP/(TP+0.5*(FP+FN))\n",
    "        if 'mcc' in metrics:\n",
    "            mcc = (TP*TN-FP*FN)/np.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "        if 'fdc' in metrics:\n",
    "            fdc = findFlakyDetectionCapacity(y_test, y_pred)\n",
    "            \n",
    "\n",
    "        index = 0\n",
    "        for category in unique:\n",
    "            if 'precision' in metrics:\n",
    "                result_dict[category]['precision'].append(precision[index])\n",
    "            if 'recall' in metrics:\n",
    "                result_dict[category]['recall'].append(recall[index])\n",
    "            if 'f1s' in metrics:\n",
    "                result_dict[category]['f1s'].append(f1score[index])\n",
    "            if 'mcc' in metrics:\n",
    "                result_dict[category]['mcc'].append(mcc[index])\n",
    "            if 'fdc' in metrics:\n",
    "                result_dict[category]['fdc'].append(fdc)\n",
    "\n",
    "            index = index + 1\n",
    "        \n",
    "    for category in unique:\n",
    "        for metric in metrics:\n",
    "            result_dict[category][metric] = sum(result_dict[category][metric])/len(result_dict[category][metric])\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Compute the entropy of input series\n",
    "\"\"\"\n",
    "def findFlakyEntropy(input):\n",
    "    entropy = 0\n",
    "\n",
    "    unique, counts = np.unique(input, return_counts=True)\n",
    "    input_dict = dict(zip(unique, counts))\n",
    "    categories = input_dict.keys()\n",
    "    base = len(categories)\n",
    "\n",
    "    for category in categories:\n",
    "        p_category = input_dict[category]/input.size\n",
    "        entropy = entropy - p_category * math.log(p_category, base)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\"\"\"\n",
    "Compute the mutual info between input series and output ndarray\n",
    "\"\"\"\n",
    "def findFlakyMutualInformation(input, output):\n",
    "    mutualInfo = 0\n",
    "\n",
    "    \"\"\"\n",
    "    categories = input.unique()\n",
    "    input_dict = input.value_counts().to_dict()\n",
    "    base = len(categories)\n",
    "    \"\"\"\n",
    "\n",
    "    unique, counts = np.unique(input, return_counts=True)\n",
    "    input_dict = dict(zip(unique, counts))\n",
    "    categories = input_dict.keys()\n",
    "    base = len(categories)\n",
    "\n",
    "    unique, counts = np.unique(output, return_counts=True)\n",
    "    output_dict = dict(zip(unique, counts))\n",
    "\n",
    "    for category in categories:\n",
    "        if category not in output_dict:\n",
    "            output_dict[category] = 0\n",
    "\n",
    "    for x_category in categories:\n",
    "        for y_category in categories:\n",
    "            index = 0 \n",
    "            xy_occurrence = 0\n",
    "            for i, v in enumerate(input):\n",
    "                if v == x_category and output[i] == y_category:\n",
    "                    xy_occurrence = xy_occurrence + 1\n",
    "                index = index +1\n",
    "            \n",
    "            p_xy = xy_occurrence/input.size\n",
    "            p_x = input_dict[x_category]/input.size\n",
    "            p_y = output_dict[y_category]/input.size\n",
    "\n",
    "            if p_xy > 0:\n",
    "                mutualInfo = mutualInfo + p_xy * math.log(p_xy/(p_x*p_y), base)\n",
    "\n",
    "    return mutualInfo\n",
    "\n",
    "\"\"\"\n",
    "Compute the flaky detection capacity from input series and output ndarray\n",
    "Based on intrusion detection capacity\n",
    "\"\"\"\n",
    "def findFlakyDetectionCapacity(input, output):\n",
    "    mutualInfo = findFlakyMutualInformation(input, output)\n",
    "    entropy = findFlakyEntropy(input)\n",
    "\n",
    "    return mutualInfo/entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_val, sampled_cat = samplingSMOTEandTL(vector_val, vector_cat)\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "lda_val = lda.fit_transform(sampled_val, sampled_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial # 0\n",
      "0.7286456450693155\n",
      "0.7212704914638588\n",
      "0.6987875751096515\n",
      "0.7154790260037667\n",
      "0.7109724716982939\n",
      "0.7135855596303327\n",
      "0.7132593809467836\n",
      "0.7239874605621601\n",
      "0.7097955198971542\n",
      "Trial # 1\n",
      "0.7309322288869923\n",
      "0.7226823168148512\n",
      "0.6993426744334827\n",
      "0.7186844067386621\n",
      "0.7091036938472769\n",
      "0.7123725082902004\n",
      "0.7122066772460819\n",
      "0.7227659752752006\n",
      "0.7085993630054092\n",
      "Trial # 2\n",
      "0.7261282730554062\n",
      "0.7208495906319681\n",
      "0.6983709205284743\n",
      "0.7144176472309984\n",
      "0.7131333175922798\n",
      "0.7169631354084657\n",
      "0.7120725637794706\n",
      "0.7245623215828099\n",
      "0.7093250356391461\n",
      "Trial # 3\n",
      "0.7256397875318796\n",
      "0.7220739661530953\n",
      "0.695739165695213\n",
      "0.7170455721462712\n",
      "0.712520113769062\n",
      "0.7143712540241836\n",
      "0.7105756465890974\n",
      "0.7213716275154971\n",
      "0.7087759898294103\n",
      "Trial # 4\n",
      "0.7274692453757965\n",
      "0.7190315461153532\n",
      "0.7013530602059139\n",
      "0.7180758146469385\n",
      "0.7105196897313096\n",
      "0.7146539577814768\n",
      "0.7123618306914911\n",
      "0.7232758219374754\n",
      "0.7063800241450016\n",
      "Trial # 5\n",
      "0.7279804889039492\n",
      "0.7210163083506006\n",
      "0.7011692021381217\n",
      "0.7165684496880621\n",
      "0.7074176812212257\n",
      "0.7126771148596461\n",
      "0.7139553355154441\n",
      "0.7235387791854918\n",
      "0.7110499117018533\n",
      "Trial # 6\n",
      "0.7316080673875673\n",
      "0.7240593895327334\n",
      "0.6992460105311958\n",
      "0.7187282705414779\n",
      "0.7092611626385136\n",
      "0.7160051677722168\n",
      "0.713713445063733\n",
      "0.7249745651148141\n",
      "0.7081856740083818\n",
      "Trial # 7\n",
      "0.7287123095523906\n",
      "0.7168451039838283\n",
      "0.6966681028916621\n",
      "0.7170366841706288\n",
      "0.7112110967578287\n",
      "0.7139109980337641\n",
      "0.711034727032682\n",
      "0.7262792557392086\n",
      "0.7138682364808995\n",
      "Trial # 8\n",
      "0.7299971777425301\n",
      "0.722565640475177\n",
      "0.7002008125554433\n",
      "0.7169163415949694\n",
      "0.7117180506123263\n",
      "0.7153634198475926\n",
      "0.7110567202773399\n",
      "0.7216724543616292\n",
      "0.7106945268574842\n",
      "Trial # 9\n",
      "0.7301913463303773\n",
      "0.7218970284628139\n",
      "0.7023986798732407\n",
      "0.718260098113154\n",
      "0.7098642366592458\n",
      "0.7143475460432062\n",
      "0.7124456395918869\n",
      "0.7266803025018909\n",
      "0.714347877338104\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Trial # \"+ str(i))\n",
    "    for config in runConfig:\n",
    "        rfc = RandomForestClassifier(\n",
    "            criterion=config[0],\n",
    "            min_impurity_decrease=config[1],\n",
    "            min_samples_leaf=config[2],\n",
    "            n_estimators=config[3],\n",
    "            random_state=0)\n",
    "        result =  runCategorySpecificKFold(rfc, 5, lda_val, sampled_cat, [ 'fdc'])\n",
    "        #print(result)\n",
    "        #f1s = 0\n",
    "        #for v in result.values():\n",
    "        #    f1s += v['mcc']\n",
    "        #print(str(f1s/len(result)))\n",
    "        print(result['ID']['fdc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is for L27 array\n",
    "\n",
    "ccp_alpha,criterion,max_depth,max_features,max_leaf_nodes,min_impurity_decrease,min_samples_leaf,min_samples_split,min_weight_fraction_leaf,n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 'gini', 5, 20, 20, 0, 'sqrt', 0, 0, None], [50, 'gini', 5, 20, 40, 0.01, 'log2', 0.001, 0.01, 50], [50, 'gini', 5, 20, 60, 0.02, None, 0.01, 0.03, 100], [50, 'entropy', 10, 40, 20, 0, 'sqrt', 0.001, 0.01, 50], [50, 'entropy', 10, 40, 40, 0.01, 'log2', 0.01, 0.03, 100], [50, 'entropy', 10, 40, 60, 0.02, None, 0, 0, None], [50, 'log_loss', 20, 60, 20, 0, 'sqrt', 0.01, 0.03, 100], [50, 'log_loss', 20, 60, 40, 0.01, 'log2', 0, 0, None], [50, 'log_loss', 20, 60, 60, 0.02, None, 0.001, 0.01, 50], [100, 'gini', 10, 60, 20, 0.01, None, 0, 0.01, 100], [100, 'gini', 10, 60, 40, 0.02, 'sqrt', 0.001, 0.03, None], [100, 'gini', 10, 60, 60, 0, 'log2', 0.01, 0, 50], [100, 'entropy', 20, 20, 20, 0.01, None, 0.001, 0.03, None], [100, 'entropy', 20, 20, 40, 0.02, 'sqrt', 0.01, 0, 50], [100, 'entropy', 20, 20, 60, 0, 'log2', 0, 0.01, 100], [100, 'log_loss', 5, 40, 20, 0.01, None, 0.01, 0, 50], [100, 'log_loss', 5, 40, 40, 0.02, 'sqrt', 0, 0.01, 100], [100, 'log_loss', 5, 40, 60, 0, 'log2', 0.001, 0.03, None], [150, 'gini', 20, 40, 20, 0.02, 'log2', 0, 0.03, 50], [150, 'gini', 20, 40, 40, 0, None, 0.001, 0, 100], [150, 'gini', 20, 40, 60, 0.01, 'sqrt', 0.01, 0.01, None], [150, 'entropy', 5, 60, 20, 0.02, 'log2', 0.001, 0, 100], [150, 'entropy', 5, 60, 40, 0, None, 0.01, 0.01, None], [150, 'entropy', 5, 60, 60, 0.01, 'sqrt', 0, 0.03, 50], [150, 'log_loss', 10, 20, 20, 0.02, 'log2', 0.01, 0.01, None], [150, 'log_loss', 10, 20, 40, 0, None, 0, 0.03, 50], [150, 'log_loss', 10, 20, 60, 0.01, 'sqrt', 0.001, 0, 100]]\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [50, 100, 150]\n",
    "criterion = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth = [5, 10, 20]\n",
    "min_samples_split = [20, 40, 60]\n",
    "min_samples_leaf = [20, 40, 60]\n",
    "min_weight_fraction_leaf = [0, 0.01, 0.02]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "min_impurity_decrease = [ 0, 0.001, 0.01]\n",
    "ccp_alpha = [0, 0.01, 0.03]\n",
    "max_leaf_nodes = [None, 50, 100]\n",
    "\n",
    "runConfig = []\n",
    "#1\n",
    "runConfig.append([n_estimators[0], criterion[0], max_depth[0], min_samples_split[0], min_samples_leaf[0], min_weight_fraction_leaf[0], max_features[0], min_impurity_decrease[0], ccp_alpha[0], max_leaf_nodes[0]])\n",
    "#2\n",
    "runConfig.append([n_estimators[0], criterion[0], max_depth[0], min_samples_split[0], min_samples_leaf[1], min_weight_fraction_leaf[1], max_features[1], min_impurity_decrease[1], ccp_alpha[1], max_leaf_nodes[1]])\n",
    "#3\n",
    "runConfig.append([n_estimators[0], criterion[0], max_depth[0], min_samples_split[0], min_samples_leaf[2], min_weight_fraction_leaf[2], max_features[2], min_impurity_decrease[2], ccp_alpha[2], max_leaf_nodes[2]])\n",
    "#4\n",
    "runConfig.append([n_estimators[0], criterion[1], max_depth[1], min_samples_split[1], min_samples_leaf[0], min_weight_fraction_leaf[0], max_features[0], min_impurity_decrease[1], ccp_alpha[1], max_leaf_nodes[1]])\n",
    "#5\n",
    "runConfig.append([n_estimators[0], criterion[1], max_depth[1], min_samples_split[1], min_samples_leaf[1], min_weight_fraction_leaf[1], max_features[1], min_impurity_decrease[2], ccp_alpha[2], max_leaf_nodes[2]])\n",
    "#6\n",
    "runConfig.append([n_estimators[0], criterion[1], max_depth[1], min_samples_split[1], min_samples_leaf[2], min_weight_fraction_leaf[2], max_features[2], min_impurity_decrease[0], ccp_alpha[0], max_leaf_nodes[0]])\n",
    "#7\n",
    "runConfig.append([n_estimators[0], criterion[2], max_depth[2], min_samples_split[2], min_samples_leaf[0], min_weight_fraction_leaf[0], max_features[0], min_impurity_decrease[2], ccp_alpha[2], max_leaf_nodes[2]])\n",
    "#8\n",
    "runConfig.append([n_estimators[0], criterion[2], max_depth[2], min_samples_split[2], min_samples_leaf[1], min_weight_fraction_leaf[1], max_features[1], min_impurity_decrease[0], ccp_alpha[0], max_leaf_nodes[0]])\n",
    "#9\n",
    "runConfig.append([n_estimators[0], criterion[2], max_depth[2], min_samples_split[2], min_samples_leaf[2], min_weight_fraction_leaf[2], max_features[2], min_impurity_decrease[1], ccp_alpha[1], max_leaf_nodes[1]])\n",
    "#10\n",
    "runConfig.append([n_estimators[1], criterion[0], max_depth[1], min_samples_split[2], min_samples_leaf[0], min_weight_fraction_leaf[1], max_features[2], min_impurity_decrease[0], ccp_alpha[1], max_leaf_nodes[2]])\n",
    "#11\n",
    "runConfig.append([n_estimators[1], criterion[0], max_depth[1], min_samples_split[2], min_samples_leaf[1], min_weight_fraction_leaf[2], max_features[0], min_impurity_decrease[1], ccp_alpha[2], max_leaf_nodes[0]])\n",
    "#12\n",
    "runConfig.append([n_estimators[1], criterion[0], max_depth[1], min_samples_split[2], min_samples_leaf[2], min_weight_fraction_leaf[0], max_features[1], min_impurity_decrease[2], ccp_alpha[0], max_leaf_nodes[1]])\n",
    "#13\n",
    "runConfig.append([n_estimators[1], criterion[1], max_depth[2], min_samples_split[0], min_samples_leaf[0], min_weight_fraction_leaf[1], max_features[2], min_impurity_decrease[1], ccp_alpha[2], max_leaf_nodes[0]])\n",
    "#14\n",
    "runConfig.append([n_estimators[1], criterion[1], max_depth[2], min_samples_split[0], min_samples_leaf[1], min_weight_fraction_leaf[2], max_features[0], min_impurity_decrease[2], ccp_alpha[0], max_leaf_nodes[1]])\n",
    "#15\n",
    "runConfig.append([n_estimators[1], criterion[1], max_depth[2], min_samples_split[0], min_samples_leaf[2], min_weight_fraction_leaf[0], max_features[1], min_impurity_decrease[0], ccp_alpha[1], max_leaf_nodes[2]])\n",
    "#16\n",
    "runConfig.append([n_estimators[1], criterion[2], max_depth[0], min_samples_split[1], min_samples_leaf[0], min_weight_fraction_leaf[1], max_features[2], min_impurity_decrease[2], ccp_alpha[0], max_leaf_nodes[1]])\n",
    "#17\n",
    "runConfig.append([n_estimators[1], criterion[2], max_depth[0], min_samples_split[1], min_samples_leaf[1], min_weight_fraction_leaf[2], max_features[0], min_impurity_decrease[0], ccp_alpha[1], max_leaf_nodes[2]])\n",
    "#18\n",
    "runConfig.append([n_estimators[1], criterion[2], max_depth[0], min_samples_split[1], min_samples_leaf[2], min_weight_fraction_leaf[0], max_features[1], min_impurity_decrease[1], ccp_alpha[2], max_leaf_nodes[0]])\n",
    "#19\n",
    "runConfig.append([n_estimators[2], criterion[0], max_depth[2], min_samples_split[1], min_samples_leaf[0], min_weight_fraction_leaf[2], max_features[1], min_impurity_decrease[0], ccp_alpha[2], max_leaf_nodes[1]])\n",
    "#20\n",
    "runConfig.append([n_estimators[2], criterion[0], max_depth[2], min_samples_split[1], min_samples_leaf[1], min_weight_fraction_leaf[0], max_features[2], min_impurity_decrease[1], ccp_alpha[0], max_leaf_nodes[2]])\n",
    "#21\n",
    "runConfig.append([n_estimators[2], criterion[0], max_depth[2], min_samples_split[1], min_samples_leaf[2], min_weight_fraction_leaf[1], max_features[0], min_impurity_decrease[2], ccp_alpha[1], max_leaf_nodes[0]])\n",
    "#22\n",
    "runConfig.append([n_estimators[2], criterion[1], max_depth[0], min_samples_split[2], min_samples_leaf[0], min_weight_fraction_leaf[2], max_features[1], min_impurity_decrease[1], ccp_alpha[0], max_leaf_nodes[2]])\n",
    "#23\n",
    "runConfig.append([n_estimators[2], criterion[1], max_depth[0], min_samples_split[2], min_samples_leaf[1], min_weight_fraction_leaf[0], max_features[2], min_impurity_decrease[2], ccp_alpha[1], max_leaf_nodes[0]])\n",
    "#24\n",
    "runConfig.append([n_estimators[2], criterion[1], max_depth[0], min_samples_split[2], min_samples_leaf[2], min_weight_fraction_leaf[1], max_features[0], min_impurity_decrease[0], ccp_alpha[2], max_leaf_nodes[1]])\n",
    "#25\n",
    "runConfig.append([n_estimators[2], criterion[2], max_depth[1], min_samples_split[0], min_samples_leaf[0], min_weight_fraction_leaf[2], max_features[1], min_impurity_decrease[2], ccp_alpha[1], max_leaf_nodes[0]])\n",
    "#26\n",
    "runConfig.append([n_estimators[2], criterion[2], max_depth[1], min_samples_split[0], min_samples_leaf[1], min_weight_fraction_leaf[0], max_features[2], min_impurity_decrease[0], ccp_alpha[2], max_leaf_nodes[1]])\n",
    "#27\n",
    "runConfig.append([n_estimators[2], criterion[2], max_depth[1], min_samples_split[0], min_samples_leaf[2], min_weight_fraction_leaf[1], max_features[0], min_impurity_decrease[1], ccp_alpha[0], max_leaf_nodes[2]])\n",
    "\n",
    "print(runConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial # 0\n",
      "0.7541918251548874\n",
      "0.7362457347724908\n",
      "0.6887154635480794\n",
      "0.7598054064442025\n",
      "0.735744104501263\n",
      "0.7463003396331283\n",
      "0.7311233445423294\n",
      "0.7555678521878387\n",
      "0.7438561160093179\n",
      "0.7450608760019906\n",
      "0.684100164361105\n",
      "0.7415366037049915\n",
      "0.7231220518101952\n",
      "0.7497023102061083\n",
      "0.7501926774121533\n",
      "0.753815559526443\n",
      "0.7502971237554926\n",
      "0.7320620067471497\n",
      "0.6827080011013539\n",
      "0.7616896128521524\n",
      "0.7418504968384126\n",
      "0.7548410700650637\n",
      "0.7445234152409927\n",
      "0.7255800504156193\n",
      "0.7451664395540509\n",
      "0.7162683165006423\n",
      "0.7494089990668987\n",
      "Trial # 1\n",
      "0.7516889724901848\n",
      "0.7385412790938526\n",
      "0.6913405349713707\n",
      "0.7632143426501845\n",
      "0.7234009672735721\n",
      "0.7432841603724978\n",
      "0.7239340691702171\n",
      "0.760041317862342\n",
      "0.7449953576280625\n",
      "0.7458644069077118\n",
      "0.6882782118667261\n",
      "0.7453363739226792\n",
      "0.7170742254711309\n",
      "0.7506864269776792\n",
      "0.7520399270952195\n",
      "0.7545031105880379\n",
      "0.7467614896264975\n",
      "0.7396231820053693\n",
      "0.6718612750064211\n",
      "0.7601388054886805\n",
      "0.7325566867071293\n",
      "0.7563848533506359\n",
      "0.7445352480114077\n",
      "0.7287222324102733\n",
      "0.7511799784929657\n",
      "0.7230729058846938\n",
      "0.7529014623408711\n",
      "Trial # 2\n",
      "0.7521989652788749\n",
      "0.7357946890232733\n",
      "0.6933293964250945\n",
      "0.7592771196267313\n",
      "0.7308369330263732\n",
      "0.7459865311961423\n",
      "0.7261317524961848\n",
      "0.7598866883083011\n",
      "0.7439692514661712\n",
      "0.7451712201667535\n",
      "0.6915662748472619\n",
      "0.7426962001147023\n",
      "0.7214458330598322\n",
      "0.7506768053030458\n",
      "0.7480024951937452\n",
      "0.7533926105972596\n",
      "0.7497249205416361\n",
      "0.7294836723292736\n",
      "0.6881334319866488\n",
      "0.7659730101394862\n",
      "0.7417721083463208\n",
      "0.7480425177675728\n",
      "0.7445534725831982\n",
      "0.743416008565234\n",
      "0.7501792419948503\n",
      "0.7222349051335559\n",
      "0.7486592789868132\n",
      "Trial # 3\n",
      "0.7480976621505786\n",
      "0.7302602039570798\n",
      "0.6880561317295556\n",
      "0.7570847934731303\n",
      "0.7325049814138415\n",
      "0.743875085872979\n",
      "0.7324865891198193\n",
      "0.7612911632542403\n",
      "0.7442060307181334\n",
      "0.7443436279057584\n",
      "0.6923641079752504\n",
      "0.7434950469268119\n",
      "0.7069380359762626\n",
      "0.7484713509294416\n",
      "0.7476786242326225\n",
      "0.754546126051719\n",
      "0.7476817414205094\n",
      "0.7278862339194295\n",
      "0.6830043606466224\n",
      "0.7614286480486969\n",
      "0.7353809478923202\n",
      "0.7543955162257865\n",
      "0.7432792015472474\n",
      "0.7352357258902043\n",
      "0.7538437470884939\n",
      "0.7088051536376253\n",
      "0.7509353938385556\n",
      "Trial # 4\n",
      "0.7477262293184799\n",
      "0.7387847182271614\n",
      "0.694434541610986\n",
      "0.7589208696227328\n",
      "0.7291553986767155\n",
      "0.7483668571529636\n",
      "0.7261104859212931\n",
      "0.7556098294922308\n",
      "0.7418884495969497\n",
      "0.7489160163820464\n",
      "0.690566991869615\n",
      "0.7387739381318716\n",
      "0.7103165029315512\n",
      "0.7461674434491208\n",
      "0.7434556852152758\n",
      "0.7502733811751661\n",
      "0.7510201207104192\n",
      "0.7407003199993972\n",
      "0.6790775128664271\n",
      "0.7566579735731921\n",
      "0.7444638123511692\n",
      "0.7506074931876396\n",
      "0.7484163549502877\n",
      "0.7265223642411626\n",
      "0.7541477773060988\n",
      "0.716695500615132\n",
      "0.7538057572695733\n",
      "Trial # 5\n",
      "0.7281048128086239\n",
      "0.7396219415366546\n",
      "0.6761098889552238\n",
      "0.7550172879666064\n",
      "0.7237089565375799\n",
      "0.7452443598555717\n",
      "0.7287701719459009\n",
      "0.7594463733836027\n",
      "0.7409576590080168\n",
      "0.7471775458857025\n",
      "0.6773894828471156\n",
      "0.7443824446714976\n",
      "0.7114124736944945\n",
      "0.750000019703232\n",
      "0.7485037819587896\n",
      "0.7535716897401402\n",
      "0.7473842932160499\n",
      "0.7208618730595225\n",
      "0.6842235609894708\n",
      "0.7608565143723942\n",
      "0.7439040974418271\n",
      "0.752401734937178\n",
      "0.7459905291409477\n",
      "0.7317953317916077\n",
      "0.7515029627631024\n",
      "0.7150321486294936\n",
      "0.750964628966495\n",
      "Trial # 6\n",
      "0.7497658800286743\n",
      "0.7377468381112458\n",
      "0.6921164775487278\n",
      "0.7551939606360742\n",
      "0.7317948016391901\n",
      "0.7435487046828666\n",
      "0.7360868073193734\n",
      "0.7593702369244036\n",
      "0.7411042151286994\n",
      "0.7444268453037509\n",
      "0.6869151745532399\n",
      "0.7455090883304212\n",
      "0.7071951104229083\n",
      "0.7506881830551025\n",
      "0.7462969817334749\n",
      "0.7537403189093327\n",
      "0.754084041909322\n",
      "0.7306662548849421\n",
      "0.6774269778871258\n",
      "0.7613575214723914\n",
      "0.7446896133792592\n",
      "0.7544798464595731\n",
      "0.747019701516108\n",
      "0.7299967557567327\n",
      "0.7522696368867291\n",
      "0.7017554110815496\n",
      "0.750272069376491\n",
      "Trial # 7\n",
      "0.7552585236892411\n",
      "0.7410392347712865\n",
      "0.6826368197540217\n",
      "0.7557201784370492\n",
      "0.7206285286130114\n",
      "0.7467648916090851\n",
      "0.7299243407096628\n",
      "0.7633945252501634\n",
      "0.7431842350501696\n",
      "0.7438178110114976\n",
      "0.6860605094128657\n",
      "0.7397745059823571\n",
      "0.7116087957265321\n",
      "0.7470940183742799\n",
      "0.7463066341907657\n",
      "0.7543828429266346\n",
      "0.742828268520115\n",
      "0.7266630590292366\n",
      "0.6877548013835865\n",
      "0.7589449438318739\n",
      "0.7414650579256705\n",
      "0.7480780841457702\n",
      "0.7488028205981275\n",
      "0.7352005757690894\n",
      "0.7490268859019266\n",
      "0.7054661493356147\n",
      "0.7478000026054633\n",
      "Trial # 8\n",
      "0.7491168898769939\n",
      "0.7353458086239212\n",
      "0.6884081604759846\n",
      "0.7600550413904001\n",
      "0.7337615669524927\n",
      "0.7464470486950561\n",
      "0.7248902422078903\n",
      "0.7539305676142262\n",
      "0.7431577990083534\n",
      "0.7447486493979812\n",
      "0.6990671051627935\n",
      "0.742195641828795\n",
      "0.7045483707749968\n",
      "0.7485080604312034\n",
      "0.7503094918239815\n",
      "0.7555714633709542\n",
      "0.7516819460348628\n",
      "0.7376975977887483\n",
      "0.6825878003810908\n",
      "0.7583234508415214\n",
      "0.7460723607474795\n",
      "0.7500077908322884\n",
      "0.7448700041534202\n",
      "0.7311110183155262\n",
      "0.7521946725047053\n",
      "0.7051627580921486\n",
      "0.7453286660143308\n",
      "Trial # 9\n",
      "0.7459185354026495\n",
      "0.7305231954138989\n",
      "0.6918209459161708\n",
      "0.7598935230587197\n",
      "0.7285145267804248\n",
      "0.7475564584226114\n",
      "0.735852107930851\n",
      "0.7609775004498179\n",
      "0.742439337146794\n",
      "0.7446346265662968\n",
      "0.6957977895000578\n",
      "0.7413246136666036\n",
      "0.7086851521822044\n",
      "0.7506784775912704\n",
      "0.7488378004172851\n",
      "0.7520914568426312\n",
      "0.750749786825898\n",
      "0.7284312054134837\n",
      "0.6841426427794317\n",
      "0.75875123663569\n",
      "0.7437568859468772\n",
      "0.7514234491213811\n",
      "0.7428184294142843\n",
      "0.7247090937438572\n",
      "0.7506998819284645\n",
      "0.7201595061449628\n",
      "0.7502537828505053\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Trial # \"+ str(i))\n",
    "    for config in runConfig:\n",
    "        rfc = RandomForestClassifier(\n",
    "            n_estimators=config[0],\n",
    "            criterion=config[1],\n",
    "            max_depth=config[2],\n",
    "            min_samples_split=config[3],\n",
    "            min_samples_leaf=config[4],\n",
    "            min_weight_fraction_leaf=config[5],\n",
    "            max_features=config[6],\n",
    "            min_impurity_decrease=config[7],\n",
    "            ccp_alpha=config[8],\n",
    "            max_leaf_nodes=config[9],\n",
    "            random_state=0)\n",
    "        result =  runCategorySpecificKFold(rfc, 5, lda_val, sampled_cat, [ 'mcc'])\n",
    "        #print(result)\n",
    "        f1s = 0\n",
    "        for v in result.values():\n",
    "            f1s += v['mcc']\n",
    "        print(str(f1s/len(result)))\n",
    "        #print(result['ID']['fdc'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
