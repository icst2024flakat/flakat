{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Compute the entropy of input series\n",
    "\"\"\"\n",
    "def findFlakyEntropy(input):\n",
    "    entropy = 0\n",
    "\n",
    "    unique, counts = np.unique(input, return_counts=True)\n",
    "    input_dict = dict(zip(unique, counts))\n",
    "    categories = input_dict.keys()\n",
    "    base = len(categories)\n",
    "\n",
    "    for category in categories:\n",
    "        p_category = input_dict[category]/input.size\n",
    "        entropy = entropy - p_category * math.log(p_category, base)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\"\"\"\n",
    "Compute the mutual info between input series and output ndarray\n",
    "\"\"\"\n",
    "def findFlakyMutualInformation(input, output):\n",
    "    mutualInfo = 0\n",
    "\n",
    "    \"\"\"\n",
    "    categories = input.unique()\n",
    "    input_dict = input.value_counts().to_dict()\n",
    "    base = len(categories)\n",
    "    \"\"\"\n",
    "\n",
    "    unique, counts = np.unique(input, return_counts=True)\n",
    "    input_dict = dict(zip(unique, counts))\n",
    "    categories = input_dict.keys()\n",
    "    base = len(categories)\n",
    "\n",
    "    unique, counts = np.unique(output, return_counts=True)\n",
    "    output_dict = dict(zip(unique, counts))\n",
    "\n",
    "    for category in categories:\n",
    "        if category not in output_dict:\n",
    "            output_dict[category] = 0\n",
    "\n",
    "    for x_category in categories:\n",
    "        for y_category in categories:\n",
    "            index = 0 \n",
    "            xy_occurrence = 0\n",
    "            for i, v in enumerate(input):\n",
    "                if v == x_category and output[i] == y_category:\n",
    "                    xy_occurrence = xy_occurrence + 1\n",
    "                index = index +1\n",
    "            \n",
    "            p_xy = xy_occurrence/input.size\n",
    "            p_x = input_dict[x_category]/input.size\n",
    "            p_y = output_dict[y_category]/input.size\n",
    "\n",
    "            if p_xy > 0:\n",
    "                mutualInfo = mutualInfo + p_xy * math.log(p_xy/(p_x*p_y), base)\n",
    "\n",
    "    return mutualInfo\n",
    "\n",
    "\"\"\"\n",
    "Compute the flaky detection capacity from input series and output ndarray\n",
    "Based on intrusion detection capacity\n",
    "\"\"\"\n",
    "def findFlakyDetectionCapacity(input, output):\n",
    "    mutualInfo = findFlakyMutualInformation(input, output)\n",
    "    entropy = findFlakyEntropy(input)\n",
    "\n",
    "    return mutualInfo/entropy\n",
    "\n",
    "\n",
    "def samplingSMOTEandTL(vector_val, vector_cat):\n",
    "    smote = SMOTE(k_neighbors=3)\n",
    "    X_smote, y_smote = smote.fit_resample(vector_val, vector_cat)\n",
    "\n",
    "    tl = TomekLinks()\n",
    "    X_tl, y_tl = tl.fit_resample(X_smote, y_smote)\n",
    "\n",
    "    return X_tl, y_tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load code2vec\n",
    "2. Run LDA\n",
    "3. Split, train and test on 10 sub test data set\n",
    "4. Store F1 score and fdc\n",
    "5. Shuffle and repeat 3 & 4\n",
    "6. For every combination of sub data set, record the consistency and discriminency\n",
    "7. Compute D and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s8/vyj613fs57b4g86vrn1xc5t80000gn/T/ipykernel_30888/1000679553.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  switchedCSV['category'] = dataCSV['category']\n",
      "/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "dataCSV = pd.read_csv('extracted-all-projects.csv')\n",
    "vectorCSV = pd.read_csv('vector.csv')\n",
    "\n",
    "raw = dataCSV['raw']\n",
    "dataCSV['id']=range(1, len(dataCSV) + 1)\n",
    "vectorCSV['id']=range(1, len(vectorCSV) + 1)\n",
    "switchedCSV = vectorCSV[['id','name','feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9','feature_10','feature_11','feature_12','feature_13','feature_14','feature_15','feature_16','feature_17','feature_18','feature_19','feature_20','feature_21','feature_22','feature_23','feature_24','feature_25','feature_26','feature_27','feature_28','feature_29','feature_30','feature_31','feature_32','feature_33','feature_34','feature_35','feature_36','feature_37','feature_38','feature_39','feature_40','feature_41','feature_42','feature_43','feature_44','feature_45','feature_46','feature_47','feature_48','feature_49','feature_50','feature_51','feature_52','feature_53','feature_54','feature_55','feature_56','feature_57','feature_58','feature_59','feature_60','feature_61','feature_62','feature_63','feature_64','feature_65','feature_66','feature_67','feature_68','feature_69','feature_70','feature_71','feature_72','feature_73','feature_74','feature_75','feature_76','feature_77','feature_78','feature_79','feature_80','feature_81','feature_82','feature_83','feature_84','feature_85','feature_86','feature_87','feature_88','feature_89','feature_90','feature_91','feature_92','feature_93','feature_94','feature_95','feature_96','feature_97','feature_98','feature_99','feature_100','feature_101','feature_102','feature_103','feature_104','feature_105','feature_106','feature_107','feature_108','feature_109','feature_110','feature_111','feature_112','feature_113','feature_114','feature_115','feature_116','feature_117','feature_118','feature_119','feature_120','feature_121','feature_122','feature_123','feature_124','feature_125','feature_126','feature_127','feature_128','feature_129','feature_130','feature_131','feature_132','feature_133','feature_134','feature_135','feature_136','feature_137','feature_138','feature_139','feature_140','feature_141','feature_142','feature_143','feature_144','feature_145','feature_146','feature_147','feature_148','feature_149','feature_150','feature_151','feature_152','feature_153','feature_154','feature_155','feature_156','feature_157','feature_158','feature_159','feature_160','feature_161','feature_162','feature_163','feature_164','feature_165','feature_166','feature_167','feature_168','feature_169','feature_170','feature_171','feature_172','feature_173','feature_174','feature_175','feature_176','feature_177','feature_178','feature_179','feature_180','feature_181','feature_182','feature_183','feature_184','feature_185','feature_186','feature_187','feature_188','feature_189','feature_190','feature_191','feature_192','feature_193','feature_194','feature_195','feature_196','feature_197','feature_198','feature_199','feature_200','feature_201','feature_202','feature_203','feature_204','feature_205','feature_206','feature_207','feature_208','feature_209','feature_210','feature_211','feature_212','feature_213','feature_214','feature_215','feature_216','feature_217','feature_218','feature_219','feature_220','feature_221','feature_222','feature_223','feature_224','feature_225','feature_226','feature_227','feature_228','feature_229','feature_230','feature_231','feature_232','feature_233','feature_234','feature_235','feature_236','feature_237','feature_238','feature_239','feature_240','feature_241','feature_242','feature_243','feature_244','feature_245','feature_246','feature_247','feature_248','feature_249','feature_250','feature_251','feature_252','feature_253','feature_254','feature_255','feature_256','feature_257','feature_258','feature_259','feature_260','feature_261','feature_262','feature_263','feature_264','feature_265','feature_266','feature_267','feature_268','feature_269','feature_270','feature_271','feature_272','feature_273','feature_274','feature_275','feature_276','feature_277','feature_278','feature_279','feature_280','feature_281','feature_282','feature_283','feature_284','feature_285','feature_286','feature_287','feature_288','feature_289','feature_290','feature_291','feature_292','feature_293','feature_294','feature_295','feature_296','feature_297','feature_298','feature_299','feature_300','feature_301','feature_302','feature_303','feature_304','feature_305','feature_306','feature_307','feature_308','feature_309','feature_310','feature_311','feature_312','feature_313','feature_314','feature_315','feature_316','feature_317','feature_318','feature_319','feature_320','feature_321','feature_322','feature_323','feature_324','feature_325','feature_326','feature_327','feature_328','feature_329','feature_330','feature_331','feature_332','feature_333','feature_334','feature_335','feature_336','feature_337','feature_338','feature_339','feature_340','feature_341','feature_342','feature_343','feature_344','feature_345','feature_346','feature_347','feature_348','feature_349','feature_350','feature_351','feature_352','feature_353','feature_354','feature_355','feature_356','feature_357','feature_358','feature_359','feature_360','feature_361','feature_362','feature_363','feature_364','feature_365','feature_366','feature_367','feature_368','feature_369','feature_370','feature_371','feature_372','feature_373','feature_374','feature_375','feature_376','feature_377','feature_378','feature_379','feature_380','feature_381','feature_382','feature_383']]\n",
    "switchedCSV['category'] = dataCSV['category']\n",
    "switchedCSV['category'].replace(np.nan, 'NonFlaky', inplace=True)\n",
    "switchedCSV = switchedCSV[(switchedCSV['category'] == 'ID') | (switchedCSV['category'] == 'UD') |(switchedCSV['category'] == 'OD') | (switchedCSV['category'] == 'OD-Vic') | (switchedCSV['category'] == 'OD-Brit') | (switchedCSV['category'] == 'NOD') | (switchedCSV['category'] == 'NDOD') | (switchedCSV['category'] == 'NODI')]\n",
    "features = ['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9','feature_10','feature_11','feature_12','feature_13','feature_14','feature_15','feature_16','feature_17','feature_18','feature_19','feature_20','feature_21','feature_22','feature_23','feature_24','feature_25','feature_26','feature_27','feature_28','feature_29','feature_30','feature_31','feature_32','feature_33','feature_34','feature_35','feature_36','feature_37','feature_38','feature_39','feature_40','feature_41','feature_42','feature_43','feature_44','feature_45','feature_46','feature_47','feature_48','feature_49','feature_50','feature_51','feature_52','feature_53','feature_54','feature_55','feature_56','feature_57','feature_58','feature_59','feature_60','feature_61','feature_62','feature_63','feature_64','feature_65','feature_66','feature_67','feature_68','feature_69','feature_70','feature_71','feature_72','feature_73','feature_74','feature_75','feature_76','feature_77','feature_78','feature_79','feature_80','feature_81','feature_82','feature_83','feature_84','feature_85','feature_86','feature_87','feature_88','feature_89','feature_90','feature_91','feature_92','feature_93','feature_94','feature_95','feature_96','feature_97','feature_98','feature_99','feature_100','feature_101','feature_102','feature_103','feature_104','feature_105','feature_106','feature_107','feature_108','feature_109','feature_110','feature_111','feature_112','feature_113','feature_114','feature_115','feature_116','feature_117','feature_118','feature_119','feature_120','feature_121','feature_122','feature_123','feature_124','feature_125','feature_126','feature_127','feature_128','feature_129','feature_130','feature_131','feature_132','feature_133','feature_134','feature_135','feature_136','feature_137','feature_138','feature_139','feature_140','feature_141','feature_142','feature_143','feature_144','feature_145','feature_146','feature_147','feature_148','feature_149','feature_150','feature_151','feature_152','feature_153','feature_154','feature_155','feature_156','feature_157','feature_158','feature_159','feature_160','feature_161','feature_162','feature_163','feature_164','feature_165','feature_166','feature_167','feature_168','feature_169','feature_170','feature_171','feature_172','feature_173','feature_174','feature_175','feature_176','feature_177','feature_178','feature_179','feature_180','feature_181','feature_182','feature_183','feature_184','feature_185','feature_186','feature_187','feature_188','feature_189','feature_190','feature_191','feature_192','feature_193','feature_194','feature_195','feature_196','feature_197','feature_198','feature_199','feature_200','feature_201','feature_202','feature_203','feature_204','feature_205','feature_206','feature_207','feature_208','feature_209','feature_210','feature_211','feature_212','feature_213','feature_214','feature_215','feature_216','feature_217','feature_218','feature_219','feature_220','feature_221','feature_222','feature_223','feature_224','feature_225','feature_226','feature_227','feature_228','feature_229','feature_230','feature_231','feature_232','feature_233','feature_234','feature_235','feature_236','feature_237','feature_238','feature_239','feature_240','feature_241','feature_242','feature_243','feature_244','feature_245','feature_246','feature_247','feature_248','feature_249','feature_250','feature_251','feature_252','feature_253','feature_254','feature_255','feature_256','feature_257','feature_258','feature_259','feature_260','feature_261','feature_262','feature_263','feature_264','feature_265','feature_266','feature_267','feature_268','feature_269','feature_270','feature_271','feature_272','feature_273','feature_274','feature_275','feature_276','feature_277','feature_278','feature_279','feature_280','feature_281','feature_282','feature_283','feature_284','feature_285','feature_286','feature_287','feature_288','feature_289','feature_290','feature_291','feature_292','feature_293','feature_294','feature_295','feature_296','feature_297','feature_298','feature_299','feature_300','feature_301','feature_302','feature_303','feature_304','feature_305','feature_306','feature_307','feature_308','feature_309','feature_310','feature_311','feature_312','feature_313','feature_314','feature_315','feature_316','feature_317','feature_318','feature_319','feature_320','feature_321','feature_322','feature_323','feature_324','feature_325','feature_326','feature_327','feature_328','feature_329','feature_330','feature_331','feature_332','feature_333','feature_334','feature_335','feature_336','feature_337','feature_338','feature_339','feature_340','feature_341','feature_342','feature_343','feature_344','feature_345','feature_346','feature_347','feature_348','feature_349','feature_350','feature_351','feature_352','feature_353','feature_354','feature_355','feature_356','feature_357','feature_358','feature_359','feature_360','feature_361','feature_362','feature_363','feature_364','feature_365','feature_366','feature_367','feature_368','feature_369','feature_370','feature_371','feature_372','feature_373','feature_374','feature_375','feature_376','feature_377','feature_378','feature_379','feature_380','feature_381','feature_382','feature_383']\n",
    "vector_val = switchedCSV[features]\n",
    "vector_cat = switchedCSV['category']\n",
    "vector_cat_val = vector_cat.values\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "lda_val = lda.fit_transform(vector_val, vector_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "\n",
    "svm_classifier = svm.SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "config = {\n",
    "    'max_features': 0.5247945548949592, \n",
    "    'max_samples': 0.6302324164385819, \n",
    "    'min_impurity_decrease': 0.0015368114684006229, \n",
    "    'min_samples_leaf': 41, \n",
    "    'min_samples_split': 40, \n",
    "    'n_estimators': 115\n",
    "    }\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    max_features=config['max_features'],\n",
    "    max_samples=config['max_samples'],\n",
    "    min_impurity_decrease=config['min_impurity_decrease'],\n",
    "    min_samples_leaf=config['min_samples_leaf'],\n",
    "    min_samples_split=config['min_samples_split'],\n",
    "    n_estimators=config['n_estimators'],\n",
    "    random_state=0)\n",
    "\n",
    "\n",
    "config = {\n",
    "    'learning_rate': 0.5433990284529154, \n",
    "    'max_depth': 17, \n",
    "    'min_samples_leaf': 88, \n",
    "    'min_samples_split': 305, \n",
    "    'n_estimators': 187\n",
    "    }\n",
    "\n",
    "gbdt = GradientBoostingClassifier(\n",
    "    learning_rate=config['learning_rate'],\n",
    "    max_depth=config['max_depth'],\n",
    "    min_samples_leaf=config['min_samples_leaf'],\n",
    "    min_samples_split=config['min_samples_split'],\n",
    "    n_estimators=config['n_estimators'],\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKFold(classifier, fold, runs):\n",
    "    sum_f1s = 0\n",
    "    sum_fdc = 0\n",
    "    result = {\"f1s\": [], \"fdc\": []}\n",
    "\n",
    "    for i in range(runs):\n",
    "            \n",
    "        kf = KFold(n_splits=fold, shuffle=True, random_state=i)   \n",
    "        for train_index, test_index in kf.split(lda_val):\n",
    "            X_train, X_test = lda_val[train_index], lda_val[test_index]\n",
    "            y_train, y_test = vector_cat_val[train_index], vector_cat_val[test_index]\n",
    "\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            \n",
    "            sum_f1s += f1_score(y_test, y_pred, average='weighted')\n",
    "            sum_fdc += findFlakyDetectionCapacity(y_test, y_pred)\n",
    "            result[\"f1s\"].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "            result[\"fdc\"].append(findFlakyDetectionCapacity(y_test, y_pred))\n",
    "            \n",
    "    C = computeC(result[\"fdc\"], result[\"f1s\"])\n",
    "    print(C)\n",
    "    D = computeD(result[\"fdc\"], result[\"f1s\"])\n",
    "    print(D)\n",
    "    \n",
    "\n",
    "def runBalancedKFold(classifier, fold, runs):\n",
    "    sum_f1s = 0\n",
    "    sum_fdc = 0\n",
    "    result = {\"f1s\": [], \"fdc\": []}\n",
    "\n",
    "    # explore the effect of size of overall calculation test size.\n",
    "    # might also try different train and test ratio\n",
    "    for i in range(runs):\n",
    "            \n",
    "        kf = KFold(n_splits=fold, shuffle=True, random_state=i)   \n",
    "        for train_index, test_index in kf.split(lda_val):\n",
    "            X_train, X_test = lda_val[train_index], lda_val[test_index]\n",
    "            y_train, y_test = vector_cat_val[train_index], vector_cat_val[test_index]\n",
    "\n",
    "            X_sampled, y_sampled = samplingSMOTEandTL(X_train, y_train)\n",
    "\n",
    "            classifier.fit(X_sampled,y_sampled)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            \n",
    "            sum_f1s += f1_score(y_test, y_pred, average='weighted')\n",
    "            sum_fdc += findFlakyDetectionCapacity(y_test, y_pred)\n",
    "            result[\"f1s\"].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "            result[\"fdc\"].append(findFlakyDetectionCapacity(y_test, y_pred))\n",
    "            \n",
    "    C = computeC(result[\"fdc\"], result[\"f1s\"])\n",
    "    print(C)\n",
    "    D = computeD(result[\"fdc\"], result[\"f1s\"])\n",
    "    print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 list\n",
    "We want to count whether fdc(a)>fdc(b) gives f1s(a)>f1s(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeC(listFDC, listF1s):\n",
    "    pairs = list(itertools.combinations(range(len(listFDC)),2))\n",
    "    consistent = 0\n",
    "    inconsistent = 0\n",
    "\n",
    "    for pair in pairs:\n",
    "        if listFDC[pair[0]] > listFDC[pair[1]] and listF1s[pair[0]] > listF1s[pair[1]]:\n",
    "            consistent += 1\n",
    "        elif listFDC[pair[0]] < listFDC[pair[1]] and listF1s[pair[0]] < listF1s[pair[1]]:\n",
    "            consistent += 1\n",
    "        else:\n",
    "            inconsistent += 1\n",
    "    C = consistent / (consistent + inconsistent)\n",
    "    return C\n",
    "\n",
    "def computeD(listFDC, listF1s):\n",
    "    pairs = list(itertools.combinations(range(len(listFDC)),2))\n",
    "    discriminant = 0\n",
    "    indiscriminant = 0\n",
    "\n",
    "    listFDC = [ round(elem, 2) for elem in listFDC ]\n",
    "    listF1s = [ round(elem, 2) for elem in listF1s ]\n",
    "\n",
    "    for pair in pairs:\n",
    "        if listFDC[pair[0]] != listFDC[pair[1]] and listF1s[pair[0]] == listF1s[pair[1]]:\n",
    "            discriminant += 1\n",
    "        elif listFDC[pair[0]] == listFDC[pair[1]] and listF1s[pair[0]] != listF1s[pair[1]]:\n",
    "            indiscriminant += 1\n",
    "    if indiscriminant == 0:\n",
    "        indiscriminant = 1\n",
    "    D = discriminant/indiscriminant\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n",
      "1.9285714285714286\n",
      "0.8566666666666667\n",
      "1.8571428571428572\n",
      "0.7733333333333333\n",
      "1.3181818181818181\n",
      "0.8233333333333334\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "runKFold(knn, 5, 5)\n",
    "runKFold(svm_classifier, 5, 5)\n",
    "runKFold(rfc, 5, 5)\n",
    "runKFold(gbdt, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8628571428571429\n",
      "2.24\n",
      "0.8571428571428571\n",
      "1.9333333333333333\n",
      "0.7861224489795918\n",
      "1.7794117647058822\n",
      "0.8122448979591836\n",
      "1.9295774647887325\n"
     ]
    }
   ],
   "source": [
    "runKFold(knn, 5, 10)\n",
    "runKFold(svm_classifier, 5, 10)\n",
    "runKFold(rfc, 5, 10)\n",
    "runKFold(gbdt, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8276767676767677\n",
      "2.029739776951673\n",
      "0.8446464646464646\n",
      "1.8847583643122676\n",
      "0.7933333333333333\n",
      "1.7207547169811321\n",
      "0.807070707070707\n",
      "2.11231884057971\n"
     ]
    }
   ],
   "source": [
    "runKFold(knn, 5, 20)\n",
    "runKFold(svm_classifier, 5, 20)\n",
    "runKFold(rfc, 5, 20)\n",
    "runKFold(gbdt, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845429718875502\n",
      "1.9169632265717675\n",
      "0.8468433734939759\n",
      "1.889022195560888\n",
      "0.7974939759036145\n",
      "1.5561766349916155\n",
      "0.8259277108433735\n",
      "1.9489795918367347\n"
     ]
    }
   ],
   "source": [
    "runKFold(knn, 5, 50)\n",
    "runKFold(svm_classifier, 5, 50)\n",
    "runKFold(rfc, 5, 50)\n",
    "runKFold(gbdt, 5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7566666666666667\n",
      "1.25\n",
      "0.8033333333333333\n",
      "2.066666666666667\n",
      "0.7766666666666666\n",
      "1.65\n",
      "0.7966666666666666\n",
      "2.125\n"
     ]
    }
   ],
   "source": [
    "runBalancedKFold(knn, 5, 5)\n",
    "runBalancedKFold(svm_classifier, 5, 5)\n",
    "runBalancedKFold(rfc, 5, 5)\n",
    "runBalancedKFold(gbdt, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7959183673469388\n",
      "2.7450980392156863\n",
      "0.773061224489796\n",
      "1.7922077922077921\n",
      "0.7534693877551021\n",
      "2.0416666666666665\n",
      "0.8367346938775511\n",
      "2.298507462686567\n"
     ]
    }
   ],
   "source": [
    "runBalancedKFold(knn, 5, 10)\n",
    "runBalancedKFold(svm_classifier, 5, 10)\n",
    "runBalancedKFold(rfc, 5, 10)\n",
    "runBalancedKFold(gbdt, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8234343434343434\n",
      "1.8856209150326797\n",
      "0.7882828282828283\n",
      "2.1241610738255035\n",
      "0.7864646464646464\n",
      "1.911854103343465\n",
      "0.7808080808080808\n",
      "1.8227848101265822\n"
     ]
    }
   ],
   "source": [
    "runBalancedKFold(knn, 5, 20)\n",
    "runBalancedKFold(svm_classifier, 5, 20)\n",
    "runBalancedKFold(rfc, 5, 20)\n",
    "runBalancedKFold(gbdt, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158072289156626\n",
      "1.9714774671990873\n",
      "0.804433734939759\n",
      "1.7717948717948717\n",
      "0.7980722891566265\n",
      "1.8634666666666666\n",
      "0.8161285140562249\n",
      "1.8624052004333695\n"
     ]
    }
   ],
   "source": [
    "runBalancedKFold(knn, 5, 50)\n",
    "runBalancedKFold(svm_classifier, 5, 50)\n",
    "runBalancedKFold(rfc, 5, 50)\n",
    "runBalancedKFold(gbdt, 5, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Test public void testDynamicDeleteException() {\n",
    "    SqlSession sqlSession=MybatisHelper.getSqlSession();\n",
    "    try{\n",
    "        CountryMapper mapper=sqlSession.getMapper(CountryMapper.class);\n",
    "        Assert.assertEquals(1,mapper.deleteByPrimaryKey(100));\n",
    "    }\n",
    "    finally{\n",
    "        sqlSession.rollback();sqlSession.close();\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
